# Домашка 1 для Otus

## Задача
1. На виртуальной машине установите любую open source CMS которая включает в себя следующие компоненты: nginx, php-fpm, database (MySQL or Postgresql)
2. На этой же виртуальной машине установите Prometheus exporters для сбора метрик со всех компонентов системы (начиная с VM и заканчивая DB, не забудьте про blackbox exporter который будет проверять доступность вашей CMS)
3. На этой же или дополнительной виртуальной машине установите Prometheus задачей которого будет раз в 5 секунд собирать метрики с экспортеров
4. На этой же или дополнительной виртуальной машине установите Alertmanager и сконфигурируйте его таким образом чтобы в случае недоступности какого либо компонента был отправлен alert с важность Critical в один из канал оповещений (канал оповещений на выбор: slack or telegram)
- Задание со звездочкой 1 (повышенная сложность) - на VM с установленной CMS слишком много “портов экспортеров торчит наружу” и они доступны всем, попробуй настроить доступ только по одному и добавить авторизацию
- Если вы выполнили задание со звездочкой номер 1 то - добавить SSL

Как развенуть CMS взято [отсюда](https://admin812.ru/razvertyvanie-wordpress-s-nginx-php-fpm-i-mariadb-s-pomoshhyu-docker-compose.html)

## требования перед запуском
  - docker
  - docker compose
  - plugin loki, ствится `make setup`

  Для удобства пользуюсь [direnv](https://github.com/direnv/direnv/blob/master/docs/installation.md).
Для создания окружения к нему выполнить `make prepare-dir-env`

## запуск 
  `make run`
## endpoints
 в качестве reverse proxy использован traefik
 саму cms спрятал за доменом http://cms.example.com/, его прописал в `/etc/hosts`
- prometheus - http://127.0.0.1/prometheus
- grafana - http://127.0.0.1/grafana
- traefik dashboard - http://127.0.0.1/dashboard/#/
- php admin для обращения к базе cms - http://127.0.0.1/database/

## exporters
- cadvisor для сбора метрик о контейнерах
- node-exporter для сбора метрик о сервер
- traefik для сбора метрик об обращениях к серверу


## пароли 
 Все пароли в Makefile, пременными в самом начале.
 (Для grafana `admin:hm1_grafana_pass`)

# Домашка 2 для Otus
## Задача
- Для выполнения данного дз воспользуйтесь наработками из предыдущего домашнего задания.
- На VM с установленным Prometheus установите Grafana последней версии доступной на момент выполнения дз
- Создайте внутри Grafana папки с названиями infra и app
- Внутри директории infra создайте дашборд который будет отображать сводную информацию по инфраструктуре (CPU, RAM, Network, etc.)
- Внутри директории app создайте дашборд который будет отображать сводную информацию о CMS (доступность компонентов, время ответа, etc.)
- Задание со звездочкой 1 - при помощи Grafana создайте alert о недоступности одного из компонентов CMS и инфраструктуры
- Задание со звездочкой 2 - создайте DrillDown dashboard который будет отображать сводную информацию по инфраструктуре, но нажав на конкретный инстанс можно получить полную информацию
- Результат: пере используйте репозиторий созданный для сдачи предыдущего ДЗ. Дополните Readme описание действий выполненных в результате выполнения данного дз. В директорию GAP-2 приложите скриншоты дашбордов которые вы создали.
## отошел от задач
  - Чтобы не мапить кучу папкок билже grafana со всем необходимыми дшбордами, в будующем правильнее иметь собранный образщ со всем что нужно и использовать его на продакшене
  - Так же сложил дашборды в одну папку не вижу смысла их раскладывать в разные
  - Дашборды сам не делал взял из [готовых](https://grafana.com/grafana/dashboards)

## результат 
скрины в Observability_homework_2023_03/homework/GAP2
blackbox exporter пока не успел настроить

# Домашка 3 для Otus
## Задача
- Для успешного выполнения ДЗ вам необходимо установить ELK (elasticsearch, logstash, kibana).
- Базовая операционная система - по вашему выбору.
- После успешной установки ELK-стека вам необходимо настроить отправку логов sshd в elasticsearch через logstash.
- Для этого вам придется изменить настройку rsyslog.
- Проверьте создался ли index в elasticsearch.
- После настройки отправки логов в ELK попробуйте настроить визуализацию логов от sshd в kibana.
- В качестве результата ДЗ принимается: конфиг rsyslog, конфиг logstash и результат проверки index в elasticsearch, а также скриншот из kibana, если получилось настроить визуализацию.

## в процессе 
- пока настроена передача логов в loki
- rsyslog и efk стэк не настроены (да скорее всего буду делать через Fluentd)
